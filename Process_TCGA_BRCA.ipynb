{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb410b1-b760-4e82-b327-91ee262c2bf8",
   "metadata": {},
   "source": [
    "### Processing TCGA-BRCA MRI exams\n",
    "\n",
    "The following script:\n",
    "* processes DCE-MRI exams in the TCGA-BRCA dataset:\n",
    "    1. figures out a pre-contrast and two post-contrast sequences\n",
    "    2. resamples them to the same anisotropic spacing of [0.7142857, 0.7142857, 1.2]\n",
    "    3. reorients them to LPS orientation\n",
    "    4. saves them to a nifti (.nii) format\n",
    "* saves breast-level labels for the dataset, i.e. whether there is breast cancer in left and right breasts\n",
    "\n",
    "Please note that this notebook will pre-process most of the DCE-MRI exams in the data set, but not all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e9f8b-0846-49c0-aaec-689d1c26bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import re\n",
    "from typing import List\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a762a-afb6-43e5-a5b4-853615849784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0. Helper functions - please run them once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73addd-9deb-45f7-bc32-515978ace503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_orientation(volume: sitk.Image) -> str:\n",
    "    orient_filter = sitk.DICOMOrientImageFilter()\n",
    "    cosines = volume.GetDirection()\n",
    "    return orient_filter.GetOrientationFromDirectionCosines(cosines)\n",
    "\n",
    "def resample_volume(volume: sitk.Image,\n",
    "                    new_spacing: List[float],\n",
    "                    interpolator=sitk.sitkLinear) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Change spacing\n",
    "    :param volume: Input image to be resampled\n",
    "    :param new_spacing: For our volumes this should be a 3-item list\n",
    "                        i.e. (1.0, 1.0, 1.0)\n",
    "    :param interpolator: Which interpolator to use. Preferred Linear,\n",
    "                        for segmentation nearest neighbor\n",
    "    \"\"\"\n",
    "    new_size = [int(round(osz*ospc/nspc)) \n",
    "                for osz, ospc, nspc \n",
    "                in zip(volume.GetSize(), volume.GetSpacing(), new_spacing)]\n",
    "    minimum_value = sitk.GetArrayFromImage(volume).min()\n",
    "    return sitk.Resample(volume,\n",
    "                         new_size,\n",
    "                         sitk.Transform(),\n",
    "                         interpolator,\n",
    "                         volume.GetOrigin(),\n",
    "                         new_spacing,\n",
    "                         volume.GetDirection(),\n",
    "                         int(minimum_value),\n",
    "                         volume.GetPixelID())\n",
    "\n",
    "def reorient_to_lps(volume: sitk.Image,\n",
    "                    verbose: bool = False) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    If volume is not in the LPS orientation, reorient to LPS\n",
    "    \"\"\"\n",
    "    current_orientation = get_volume_orientation(volume)\n",
    "    if current_orientation != \"LPS\":\n",
    "        if verbose:\n",
    "            print(f\"Reorienting {current_orientation} to LPS\")\n",
    "            reorient_time = time.time()\n",
    "        orientation_filter = sitk.DICOMOrientImageFilter()\n",
    "        orientation_filter.SetDesiredCoordinateOrientation(\"LPS\")\n",
    "        volume = orientation_filter.Execute(volume)\n",
    "        if verbose:\n",
    "            reorient_time_end = time.time()\n",
    "            print(\"Reotienting time:\", reorient_time_end - reorient_time)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52eb053-f2d4-47a9-8e05-8f8a2a9927ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multivolume(studydir):\n",
    "    subvolumes = {}\n",
    "    \n",
    "    # This flag should be set to True if processing is complete\n",
    "    # and subvolumes(dict) is properly propagated\n",
    "    subvolumes_generated = False\n",
    "    \n",
    "    # Initially, check filenames for format D-DDD.dcm (D=digit)\n",
    "    # a lot of studies will have sub-volumes separated by this format\n",
    "    # e.g. 1-DDD.dcm for pre-contrast, 2-DDD.dcm for first post-contrast,\n",
    "    # 3-DDD.dcm for second post-contrast etc.\n",
    "    for dn in sorted(os.listdir(studydir)):\n",
    "        if not re.match(r\"\\d-\\d\\d\\d.dcm\", dn):\n",
    "            print(\"\\tNot matched regexp:\", dn)\n",
    "            break\n",
    "        else:   # matched\n",
    "            if dn[0] not in subvolumes:\n",
    "                subvolumes[dn[0]] = []\n",
    "            subvolumes[dn[0]].append(dn)\n",
    "    \n",
    "    # If we were able to generate initial subvolumes\n",
    "    # using filenames\n",
    "    if len(subvolumes) > 0:       \n",
    "        # Option one: There are multiple subvolumes (<2), each should have\n",
    "        # an even number of images\n",
    "        if len(subvolumes) > 1:\n",
    "            images_num_to_match = None\n",
    "            failed_check = False\n",
    "            for k, v in subvolumes.items():\n",
    "                if images_num_to_match is None:\n",
    "                    images_num_to_match = len(v)\n",
    "                else:\n",
    "                    if len(v) != images_num_to_match:\n",
    "                        print(\"\\tOption 1 failed.\")\n",
    "                        failed_check = True\n",
    "            if not failed_check:\n",
    "                subvolumes_generated = True\n",
    "                print(\"Option 1 successful.\")\n",
    "                return subvolumes\n",
    "            else:\n",
    "                print(\"\\tOption 1 failed!\")\n",
    "        \n",
    "        # Option two: There is first subvolume format (1-DDD.dcm) for precontrast\n",
    "        # and then second subvolume (2-DDD.dcm) for postcontrast.\n",
    "        if len(subvolumes) == 2:\n",
    "            print(\"\\t Running failed_check\")\n",
    "            new_subvolumes = {}\n",
    "            potential_num_prec = subvolumes[\"1\"]\n",
    "            new_subvolumes[\"1\"] = subvolumes[\"1\"]\n",
    "            print(\"\\t division modulo:\", len(subvolumes[\"2\"]) % len(subvolumes[\"1\"]))\n",
    "            if len(subvolumes[\"2\"]) % len(subvolumes[\"1\"]) == 0:\n",
    "                failed_check = False  # match!\n",
    "                postcontrast_num_subvolumes = len(subvolumes[\"2\"]) // len(subvolumes[\"1\"])\n",
    "                for i in range(2, 2+postcontrast_num_subvolumes):\n",
    "                    new_subvolumes[str(i)] = [f\"2-{i:03}.dcm\" for i in range((i-1)*len(subvolumes[\"1\"])+1,i*len(subvolumes[\"1\"])+1)]\n",
    "                print(f\"\\tNew subvolumes:\\n\\t{new_subvolumes}\")\n",
    "                subvolumes_generated = True\n",
    "            if subvolumes_generated:\n",
    "                print(\"Option 2 successful.\")\n",
    "                return new_subvolumes\n",
    "            else:\n",
    "                raise ValueError(\"Subvolumes=2 but failed to process.\")\n",
    "    \n",
    "    # Check for TriggerTime policy\n",
    "    # this is slow because we have to read each DICOM file to check for TriggerTime tag\n",
    "    if len(subvolumes) <= 1:\n",
    "        print(\"\\tTrying trigger time policy...\")\n",
    "        \n",
    "        tt = {}  # dictionary of structure: key is trigger time, value is a list of filenames\n",
    "        \n",
    "        for dn in sorted(os.listdir(studydir)):\n",
    "            ds = pydicom.dcmread(os.path.join(studydir, dn))            \n",
    "\n",
    "            if ds.TriggerTime not in tt:\n",
    "                tt[ds.TriggerTime] = []\n",
    "            tt[ds.TriggerTime].append(dn)\n",
    "\n",
    "        # Check that all subvolumes generated from trigger time\n",
    "        # have the same number of images\n",
    "        check_failed = False\n",
    "        num_expected = None\n",
    "        for k, v in tt.items():\n",
    "            if num_expected is None:\n",
    "                num_expected = len(v)\n",
    "            else:\n",
    "                if len(v) != num_expected:\n",
    "                    check_failed = True\n",
    "        if check_failed:\n",
    "            print(\"\\tTriggerTime policy failed.\")\n",
    "        else:\n",
    "            print(\"\\tTriggerTime successful.\")\n",
    "            tt = dict(sorted(tt.items()))  # sort by key (trigger time)\n",
    "            \n",
    "            k_i = 1\n",
    "            tt_keys = list(tt.keys())\n",
    "            for k in tt_keys:\n",
    "                tt[str(k_i)] = tt.pop(k)\n",
    "                k_i += 1\n",
    "            \n",
    "            return tt\n",
    "    \n",
    "    # If the function hasn't returned subvolume dict yet,\n",
    "    # then we failed and nothing has been processed.\n",
    "    \n",
    "    print(\"\\tMulti-volume processing failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd5d11-4526-4451-b5e2-cb1c906970c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_given_filepaths(filepaths: list, reorient_resample=True):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    reader.SetFileNames(filepaths)\n",
    "    volume = reader.Execute()\n",
    "    \n",
    "    if reorient_resample:\n",
    "        print(\"Image size before:\", volume.GetSize())\n",
    "        volume = reorient_to_lps(volume)\n",
    "        volume = resample_volume(volume, [0.7142857, 0.7142857, 1.2])\n",
    "        print(\"Image size after:\", volume.GetSize())\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f843b-79a6-4528-a452-4bbb6b73c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_study_dir(studydir, resample=True):\n",
    "    print(\"READING: \", studydir)\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_names = reader.GetGDCMSeriesFileNames(studydir)\n",
    "    #print(dicom_names)\n",
    "    reader.SetFileNames(dicom_names)\n",
    "\n",
    "    series_volume = reader.Execute()\n",
    "    \n",
    "    print(\"Image size before:\", series_volume.GetSize())\n",
    "    \n",
    "    # Reorient to LPS\n",
    "    series_volume = reorient_to_lps(series_volume)\n",
    "    print(\"Image size post reorient:\", series_volume.GetSize())\n",
    "    \n",
    "    # Resample to new spacing\n",
    "    if resample:\n",
    "        series_volume = resample_volume(volume=series_volume, new_spacing=[0.7142857, 0.7142857, 1.2])\n",
    "    \n",
    "    size = series_volume.GetSize()\n",
    "    #print(\"Image size after:\", size[0], size[1], size[2])\n",
    "    \n",
    "    return series_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d44a7-d689-4279-8c1a-cec572d2e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_serie_dirnames(subject, study_id, pre_post_dict, basedir):\n",
    "    \"\"\"\n",
    "    This returns a dictionary in structure:\n",
    "        t1pre: [dirnames where all pre-c images are],\n",
    "        t1c1: [dirnames where all 1st post-c images are],\n",
    "        t1c2: [dirnames where all 2st post-c images are],\n",
    "    \"\"\"\n",
    "    study_dicom_dir = os.path.join(basedir, subject, study_id)\n",
    "    \n",
    "    study_yaml = pre_post_dict['subjects'][subject]['studies'][study_id]\n",
    "    series_yaml = study_yaml['series']\n",
    "    \n",
    "    serie_dirname_dict = {\n",
    "        \"t1pre\": [],\n",
    "        \"t1c1\": [],\n",
    "        \"t1c2\": []\n",
    "    }\n",
    "    serie_dir_names = os.listdir(study_dicom_dir)\n",
    "   \n",
    "    for serie_num, serie_type in series_yaml.items():\n",
    "        if serie_type in serie_dirname_dict:\n",
    "            # 1. find the dirname\n",
    "            for serie_dn in serie_dir_names:\n",
    "                if serie_dn.startswith(f\"{str(serie_num)}.0\"):\n",
    "                    # 2. add to the dict\n",
    "                    serie_dirname_dict[serie_type].append(serie_dn)\n",
    "    \n",
    "    return serie_dirname_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7375a7-e91e-43af-bcb8-4c3f8ab74379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_volumes_split_bilateral(subject, study_id, serie_dirnames, basedir, reorient_resample=True):   \n",
    "    sitk_dict = {}  # this will keep simpleitk images\n",
    "    \n",
    "    for serie_type in ['t1pre', 't1c1', 't1c2']:\n",
    "        arrs = []\n",
    "\n",
    "        # assumes that spacing and direction are the same for both volumes\n",
    "        # NOTE: Maybe there should be a sanity check here that both are same/similar\n",
    "        spacing = None\n",
    "        direction = None\n",
    "\n",
    "        for single_dir in serie_dirnames[serie_type]:\n",
    "            serie_full_path = os.path.join(basedir, subject, study_id, single_dir)\n",
    "            serie_files = [os.path.join(serie_full_path, x) for x in sorted(os.listdir(serie_full_path))]\n",
    "\n",
    "            vol = get_volume_given_filepaths(serie_files, reorient_resample=False)\n",
    "\n",
    "            if spacing is None:\n",
    "                spacing = vol.GetSpacing()\n",
    "                direction = vol.GetDirection()\n",
    "\n",
    "            arrs.append(sitk.GetArrayFromImage(vol))\n",
    "\n",
    "        # combine both to numpy array\n",
    "        stacked = np.vstack(arrs)\n",
    "\n",
    "        # convert back to simpleitk\n",
    "        stacked_sitk = sitk.GetImageFromArray(stacked)\n",
    "\n",
    "        stacked_sitk.SetSpacing(spacing)\n",
    "        stacked_sitk.SetDirection(direction)\n",
    "        \n",
    "        if reorient_resample:\n",
    "            stacked_sitk = reorient_to_lps(stacked_sitk)\n",
    "            stacked_sitk = resample_volume(stacked_sitk, [0.7142857, 0.7142857, 1.2])\n",
    "        \n",
    "        sitk_dict[serie_type] = stacked_sitk\n",
    "        \n",
    "    return sitk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87874eb-744b-4a8c-8482-d3fbb39fd1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_tcga_brca(pre_post_dict, data_basedir, save_basedir, dry_run=False, verbose=False):\n",
    "    processed_studies = 0\n",
    "    study_paths_dict = {}\n",
    "    \n",
    "    if dry_run:\n",
    "        print(\"Dry run, no actual processing will be done.\")\n",
    "    with tqdm(total=139) as pbar:\n",
    "        for subject in pre_post_dict['subjects']:\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f\"P: {subject}\")\n",
    "            \n",
    "            # Get studies for subject\n",
    "            try:\n",
    "                s_studies = pre_post_dict['subjects'][subject]['studies']        \n",
    "            except:\n",
    "                print(f\"[{subject}] has no correct studies\")\n",
    "                continue\n",
    "                \n",
    "            # Iterate over all expected studies for this subject\n",
    "            for study_id in s_studies:\n",
    "                pbar.set_description(f\"P: {subject}, S: {study_id}\")\n",
    "                \n",
    "                if os.path.exists(os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"))):\n",
    "                    # Skip if already saved\n",
    "                    if verbose:\n",
    "                        print(f\"[{subject}/{study_id}] already saved -- skipping\")\n",
    "                    continue\n",
    "\n",
    "                study = s_studies[study_id]\n",
    "                \n",
    "                # Get laterality type\n",
    "                try:\n",
    "                    lat_type = study['lateralityType']\n",
    "                except:\n",
    "                    print(f\"[{subject}/{study_id}] does not have lateralityType value.\")\n",
    "                    continue\n",
    "                if lat_type == 'unknown':\n",
    "                    print(f\"[{subject}/{study_id}] has unknown laterality. Excluding.\")\n",
    "                    continue\n",
    "                \n",
    "                # Get info about all series for current study\n",
    "                series = study['series']\n",
    "                \n",
    "                # PROCESSING OF EACH SERIE DEPENDING ON TYPE OF LATERALITY IN IMAGES\n",
    "                # (This is where the actual processing happens)\n",
    "                if verbose:\n",
    "                    print(f\"[{subject}/{study_id}]: laterality type {lat_type}\")\n",
    "                if dry_run:\n",
    "                    continue\n",
    "                \n",
    "                if lat_type == 'splitBilateral':\n",
    "                    print(f\"Lat type {lat_type} is not handled by this script.\")\n",
    "                    continue  # Continue to next series\n",
    "                elif lat_type == 'bilateral':\n",
    "                    check_pre = False\n",
    "                    check_c1 = False\n",
    "                    check_c2 = False\n",
    "\n",
    "                    for serie_id, serie_type in series.items():\n",
    "                        #print(serie_id, serie_type)\n",
    "                        if serie_type == 't1pre':\n",
    "                            check_pre = serie_id\n",
    "                        elif serie_type == 't1c1':\n",
    "                            check_c1 = serie_id\n",
    "                        elif serie_type == 't1c2':\n",
    "                            check_c2 = serie_id\n",
    "                    assert check_pre and check_c1 and check_c2\n",
    "                    \n",
    "                    study_dicom_dir = os.path.join(data_basedir, subject, study_id)\n",
    "                    serie_dir_names = os.listdir(study_dicom_dir)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"pre: {check_pre}, t1c1: {check_c1}, t1c2: {check_c2}\")\n",
    "                    for serie_dn in serie_dir_names:\n",
    "                        if serie_dn.startswith(f\"{str(check_pre)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "                            if verbose:\n",
    "                                print(f\"[{subject}/{study_id}] T1pre directory: {full_serie_dir_path}\")\n",
    "                            serie_volume = read_study_dir(full_serie_dir_path)\n",
    "                            pathlib.Path(os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"))).mkdir(parents=True, exist_ok=True)\n",
    "                            sitk.WriteImage(serie_volume, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1pre.nii.gz\"))\n",
    "                        elif serie_dn.startswith(f\"{str(check_c1)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "                            if verbose:\n",
    "                                print(f\"[{subject}/{study_id}] T1c1 directory: {full_serie_dir_path}\")\n",
    "                            serie_volume = read_study_dir(full_serie_dir_path)\n",
    "                            pathlib.Path(os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"))).mkdir(parents=True, exist_ok=True)\n",
    "                            sitk.WriteImage(serie_volume, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1c1.nii.gz\"))\n",
    "                        elif serie_dn.startswith(f\"{str(check_c2)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "                            if verbose:\n",
    "                                print(f\"[{subject}/{study_id}] T1c2 directory: {full_serie_dir_path}\")\n",
    "                            serie_volume = read_study_dir(full_serie_dir_path)\n",
    "                            pathlib.Path(os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"))).mkdir(parents=True, exist_ok=True)\n",
    "                            sitk.WriteImage(serie_volume, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1c2.nii.gz\"))\n",
    "                        else:\n",
    "                            # not matched\n",
    "                            continue\n",
    "                    \n",
    "                    processed_studies += 1\n",
    "                elif lat_type == 'multiVolumeBilateral':\n",
    "                     # Establish series numbers\n",
    "                    sid_pre = False\n",
    "                    sid_multivolume_postcontrast = False\n",
    "                    sid_multivolume_all = False\n",
    "\n",
    "                    for serie_id, serie_type in series.items():\n",
    "                        if serie_type == 't1pre':\n",
    "                            sid_pre = serie_id\n",
    "                        elif serie_type == 'multiVolumeT1':\n",
    "                            sid_multivolume_all = serie_id\n",
    "                        elif serie_type == 'multiVolumeT1Postcontrast':\n",
    "                            sid_multivolume_postcontrast = serie_id\n",
    "\n",
    "                    if sid_pre:\n",
    "                        assert sid_multivolume_all is False  # if pre-c is separate, there cannot be a \"Full\" multivolume\n",
    "                        assert sid_multivolume_postcontrast is not False  # if pre-c is separate, there has to be a \"post-c\" multivolume\n",
    "                        if verbose:\n",
    "                            print(f\"[{subject}/{study_id}] pre: {sid_pre}; post: {sid_multivolume_postcontrast}\")\n",
    "                    else:\n",
    "                        print(f\"[{subject}/{study_id}] full: {sid_multivolume_all}\")\n",
    "\n",
    "                    study_dicom_dir = os.path.join(data_basedir, subject, study_id)  # boilerplate\n",
    "                    serie_dir_names = os.listdir(study_dicom_dir)  # boilerplate\n",
    "\n",
    "                    subvolume_dict = {}\n",
    "                    for serie_dn in serie_dir_names:\n",
    "                        if serie_dn.startswith(f\"{str(sid_pre)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "                            print(f\"[{subject}/{study_id}] ...multi-volume pre-c\")\n",
    "                            subvolume_dict[\"pre\"] = [os.path.join(full_serie_dir_path, x) for x in sorted(os.listdir(full_serie_dir_path))]\n",
    "\n",
    "                        elif serie_dn.startswith(f\"{str(sid_multivolume_postcontrast)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "                            print(f\"[{subject}/{study_id}] ...multi-volume post-c\")\n",
    "                            subvolume_dict[\"post\"] = process_multivolume(full_serie_dir_path)\n",
    "                            for post_i, (_, v) in enumerate(subvolume_dict[\"post\"].items()):\n",
    "                                subvolume_dict[f\"post{post_i+1}\"] = [os.path.join(full_serie_dir_path, x) for x in v]\n",
    "                            del subvolume_dict[\"post\"]\n",
    "\n",
    "                        elif serie_dn.startswith(f\"{str(sid_multivolume_all)}.0\"):\n",
    "                            full_serie_dir_path = os.path.join(study_dicom_dir, serie_dn)\n",
    "\n",
    "                            subvolume_dict = process_multivolume(full_serie_dir_path)\n",
    "                            print(f\"[{subject}/{study_id}] multi-volume processed correctly.\")\n",
    "\n",
    "                    study_paths_dict[study_id] = subvolume_dict\n",
    "\n",
    "                    if sid_pre:\n",
    "                        expected_img_num = len(subvolume_dict[\"pre\"])\n",
    "                        for ss, l in subvolume_dict.items():\n",
    "                            assert(expected_img_num) == len(l)\n",
    "\n",
    "                        # Save separate volumes\n",
    "                        volume_pre = get_volume_given_filepaths(subvolume_dict[\"pre\"])\n",
    "                        volume_post1 = get_volume_given_filepaths(subvolume_dict[\"post1\"])\n",
    "                        volume_post2 = get_volume_given_filepaths(subvolume_dict[\"post2\"])\n",
    "                    else:\n",
    "                        volume_pre = get_volume_given_filepaths([os.path.join(full_serie_dir_path, x) for x in subvolume_dict[\"1\"]])\n",
    "                        volume_post1 = get_volume_given_filepaths([os.path.join(full_serie_dir_path, x) for x in subvolume_dict[\"2\"]])\n",
    "                        volume_post2 = get_volume_given_filepaths([os.path.join(full_serie_dir_path, x) for x in subvolume_dict[\"3\"]])\n",
    "\n",
    "                    # create directory\n",
    "                    pathlib.Path(os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"))).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    # save volume\n",
    "                    sitk.WriteImage(volume_pre, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1pre.nii.gz\"))\n",
    "                    sitk.WriteImage(volume_post1, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1c1.nii.gz\"))\n",
    "                    sitk.WriteImage(volume_post2, os.path.join(save_basedir, f\"{subject}___{study_id}\".replace(\" \", \"_\"), f\"{serie_id}-t1c2.nii.gz\"))\n",
    "\n",
    "                    processed_studies += 1\n",
    "                elif lat_type in ['unilateralLeft', 'unilateralRight', 'multiVolumeUnilateralLeft', 'multiVolumeUnilateralRight']:\n",
    "                    print(f\"[{subject}/{study_id}] EXCLUDED because of lat type {lat_type}. (This script excludes unilateral exams)\")\n",
    "        print(processed_studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e22c6e-2865-41bf-a239-7e2da9767e12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Download the dataset\n",
    "You can download the TCGA-BRCA dataset from The Cancer Imaging Archive (TCIA) website: https://wiki.cancerimagingarchive.net/display/Public/TCGA-BRCA\n",
    "\n",
    "Make sure that you download both imaging files as well as the Clinical Data zip file.\n",
    "\n",
    "### 2. Provide paths to downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6faca2-3900-4036-90ba-e46099c67a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide path where your TCGA-BRCA dataset is downloaded\n",
    "base_dir = \"/path/to/your/tcgabrca/dataset/TCGA-BRCA/\"\n",
    "\n",
    "# Please find file named `nationwidechildrens.org_clinical_patient_brca.txt`\n",
    "# and provide path to the file below:\n",
    "clinical_file = \"/path/to/clinical/file/nationwidechildrens.org_clinical_patient_brca.txt\"\n",
    "\n",
    "# Provide path to a directory where you want to save \n",
    "# preprocessed images\n",
    "output_dir = \"/path/where/to/save/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6139c-72bc-4560-9de4-353997a0bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file that identifies all pre- and post-contrast series types\n",
    "with open(\"tcga_brca_key.yaml\", \"r\") as f:\n",
    "    pre_post_dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcc78c-dac3-4232-9630-980c21d4a6a4",
   "metadata": {},
   "source": [
    "### 3. Check completeness of download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cc42a-cce3-4d19-bcab-310aeae37107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete download should consist of 139 subjects.\")\n",
    "print(f\"Found {len(os.listdir(base_dir))} subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a70ce-2ef2-4210-918b-fa169fe64830",
   "metadata": {},
   "source": [
    "### 4. Pre-process downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a11888-30fd-4a84-81de-a53fd1a49c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_tcga_brca(\n",
    "    pre_post_dict, \n",
    "    data_basedir=base_dir,\n",
    "    save_basedir=output_dir,\n",
    "    dry_run=False, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6eb02e-8552-4898-b140-6029e6b00853",
   "metadata": {},
   "source": [
    "### 5. Generate a datalist for training\n",
    "This part generates a DataFrame with paths to your nifti images and correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd762158-8029-4b3b-9c46-298d7abe7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datalist = {}\n",
    "df = pd.read_csv(clinical_file, delimiter=\"\\t\")\n",
    "df = df[['bcr_patient_barcode', 'patient_id', 'anatomic_neoplasm_subdivision', \n",
    "    'menopause_status', 'ajcc_tumor_pathologic_pt', 'ajcc_nodes_pathologic_pn',\n",
    "    'ajcc_metastasis_pathologic_pm', 'er_status_by_ihc', 'er_status_ihc_Percent_Positive', 'er_ihc_score',\n",
    "    'pr_positivity_ihc_intensity_score', 'her2_ihc_score']][2:]\n",
    "\n",
    "for study_dir in sorted(os.listdir(output_dir)):\n",
    "    new_datalist[study_dir] = {\n",
    "        \"label\": None,\n",
    "        \"path_pre\": None,\n",
    "        \"path_post1\": None,\n",
    "        \"path_post2\": None        \n",
    "    }\n",
    "    \n",
    "    # Store paths\n",
    "    for f in os.listdir(os.path.join(output_dir, study_dir)):\n",
    "        if \"t1pre\" in f:\n",
    "            new_datalist[study_dir]['path_pre'] = os.path.join(output_dir, study_dir, f)\n",
    "        elif \"t1c1\" in f:\n",
    "            new_datalist[study_dir]['path_post1'] = os.path.join(output_dir, study_dir, f)\n",
    "        elif \"t1c2\" in f:\n",
    "            new_datalist[study_dir]['path_post2'] = os.path.join(output_dir, study_dir, f)\n",
    "    \n",
    "    # Store labels\n",
    "    for key in new_datalist.keys():\n",
    "        patient_id = key[8:12]\n",
    "        df_x = df[df.patient_id == patient_id]\n",
    "        anatomic_loc = df_x.iloc[0].anatomic_neoplasm_subdivision\n",
    "        if \"left\" in anatomic_loc.lower():\n",
    "            new_datalist[key]['label'] = [0, 1, 0, 0]\n",
    "        elif \"right\" in anatomic_loc.lower():\n",
    "            new_datalist[key]['label'] = [0, 0, 0, 1]\n",
    "        else:\n",
    "            raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f878a1-afe3-480d-865e-e986fed67232",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_df = pd.DataFrame.from_dict(new_datalist, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c5495-4513-4362-bd66-2c2c15307d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
